# Book Ingestion Workflow - Vault / Book Collection RAG Pipeline
#
# Processes a PDF book from Google Cloud Storage: downloads, extracts text,
# chunks it intelligently, generates embeddings, and stores in pgVector.
# Sends API callbacks (GraphQL mutations) to update document status.
#
# Run via CLI:
#   lexflow examples/showcase/vault/ingest_book.yaml \
#     --input bucket=mvp-personal-vault \
#     --input objeto=solar_system.pdf \
#     --input livro_id=solar-system-001 \
#     --input projeto_gcp=inspira-development \
#     --input document_id=6980e6a96e32a63d0a13972c \
#     --input workspace_id=62b9d55915370b1b00a1f86b \
#     --input file_name=solar_system.pdf \
#     --input api_token=YOUR_JWT_TOKEN
#
# Requirements:
#   pip install lexflow[pgvector,gcs]
#   gcloud auth application-default login

workflows:
  - name: main
    interface:
      inputs: [bucket, objeto, livro_id, projeto_gcp, pgvector_dsn, collection, chunk_size, overlap, document_id, workspace_id, file_name, api_token, api_url]
      outputs: []
    variables:
      # Input parameters
      bucket: ""
      objeto: ""
      livro_id: ""
      projeto_gcp: ""
      pgvector_dsn: "postgresql://vault:vault@localhost/vault"
      collection: "livros"
      chunk_size: 1000
      overlap: 200
      document_id: ""
      workspace_id: ""
      file_name: ""
      api_token: ""
      api_url: "http://localhost:4000/graphql"
      # State variables
      gcs_client: null
      pdf_bytes: null
      pgvector_pool: null
      pdf_pages: []
      chunks: []
      chunk_texts: []
      chunk_count: 0
      page_count: 0
      embeddings: []
      ids: []
      payloads: []
      metadata: {}
      build_result: {}
      source_path: ""
      callback_body: ""
      callback_result: null
      error_msg: ""
      # Timing variables
      pipeline_t0: 0
      step1_t0: 0
      step2_t0: 0
      step3_t0: 0
      step4_t0: 0
      step5_t0: 0
      step6_t0: 0
      step7_t0: 0
      step8_t0: 0
      step_t1: 0
    nodes:
      start:
        opcode: workflow_start
        next: build_source_path
        inputs: {}

      # Build source path for display (gs://bucket/objeto)
      source_path_prefix:
        opcode: operator_add
        isReporter: true
        inputs:
          left:
            literal: "gs://"
          right:
            variable: bucket

      source_path_full:
        opcode: operator_add
        isReporter: true
        inputs:
          left:
            node: source_path_prefix
          right:
            node: source_path_suffix

      source_path_suffix:
        opcode: operator_add
        isReporter: true
        inputs:
          left:
            literal: "/"
          right:
            variable: objeto

      build_source_path:
        opcode: data_set_variable_to
        next: save_pipeline_start
        inputs:
          VARIABLE:
            literal: "source_path"
          VALUE:
            node: source_path_full

      # ========================================================================
      # PIPELINE START TIME
      # ========================================================================
      get_pipeline_start:
        opcode: util_time_now
        isReporter: true
        inputs: {}

      save_pipeline_start:
        opcode: data_set_variable_to
        next: print_header
        inputs:
          VARIABLE:
            literal: "pipeline_t0"
          VALUE:
            node: get_pipeline_start

      # ========================================================================
      # HEADER
      # ========================================================================
      print_header:
        opcode: io_print
        next: print_separator
        inputs:
          STRING:
            literal: "\n================================================================================\n"

      print_separator:
        opcode: io_print
        next: print_title
        inputs:
          STRING:
            literal: "                   VAULT - BOOK INGESTION PIPELINE\n"

      print_title:
        opcode: io_print
        next: print_settings_header
        inputs:
          STRING:
            literal: "================================================================================\n\n"

      # Print settings
      print_settings_header:
        opcode: io_print
        next: print_bucket
        inputs:
          STRING:
            literal: "Settings:\n"

      format_bucket:
        opcode: operator_add
        isReporter: true
        inputs:
          left:
            literal: "  Bucket:      "
          right:
            node: bucket_with_newline

      bucket_with_newline:
        opcode: operator_add
        isReporter: true
        inputs:
          left:
            variable: bucket
          right:
            literal: "\n"

      print_bucket:
        opcode: io_print
        next: print_objeto
        inputs:
          STRING:
            node: format_bucket

      format_objeto:
        opcode: operator_add
        isReporter: true
        inputs:
          left:
            literal: "  Objeto:      "
          right:
            node: objeto_with_newline

      objeto_with_newline:
        opcode: operator_add
        isReporter: true
        inputs:
          left:
            variable: objeto
          right:
            literal: "\n"

      print_objeto:
        opcode: io_print
        next: print_livro_id
        inputs:
          STRING:
            node: format_objeto

      format_livro_id:
        opcode: operator_add
        isReporter: true
        inputs:
          left:
            literal: "  Livro ID:    "
          right:
            node: livro_id_with_newline

      livro_id_with_newline:
        opcode: operator_add
        isReporter: true
        inputs:
          left:
            variable: livro_id
          right:
            literal: "\n"

      print_livro_id:
        opcode: io_print
        next: print_collection
        inputs:
          STRING:
            node: format_livro_id

      format_collection:
        opcode: operator_add
        isReporter: true
        inputs:
          left:
            literal: "  Collection:  "
          right:
            node: collection_with_newline

      collection_with_newline:
        opcode: operator_add
        isReporter: true
        inputs:
          left:
            variable: collection
          right:
            literal: "\n\n"

      print_collection:
        opcode: io_print
        next: save_step1_start
        inputs:
          STRING:
            node: format_collection

      # ========================================================================
      # Bearer auth headers (reused by PROCESSING and INDEXED callbacks)
      # ========================================================================
      clean_api_token:
        opcode: string_trim
        isReporter: true
        inputs:
          text:
            variable: api_token

      build_auth_prefix:
        opcode: operator_add
        isReporter: true
        inputs:
          left:
            literal: "Bearer "
          right:
            node: clean_api_token

      callback_headers_base:
        opcode: dict_create
        isReporter: true
        inputs: {}

      callback_headers_with_auth:
        opcode: dict_set
        isReporter: true
        inputs:
          d:
            node: callback_headers_base
          key:
            literal: "Authorization"
          value:
            node: build_auth_prefix

      callback_headers:
        opcode: dict_set
        isReporter: true
        inputs:
          d:
            node: callback_headers_with_auth
          key:
            literal: "Content-Type"
          value:
            literal: "application/json"

      # ========================================================================
      # STEP 1: Callback PROCESSING status to API
      # ========================================================================
      get_step1_start:
        opcode: util_time_now
        isReporter: true
        inputs: {}

      save_step1_start:
        opcode: data_set_variable_to
        next: try_callback_processing
        inputs:
          VARIABLE:
            literal: "step1_t0"
          VALUE:
            node: get_step1_start

      # Build GraphQL mutation body for PROCESSING status
      build_processing_query:
        opcode: operator_add
        isReporter: true
        inputs:
          left:
            literal: 'mutation { updateDocumentStatus(input: { documentId: "'
          right:
            node: processing_query_2

      processing_query_2:
        opcode: operator_add
        isReporter: true
        inputs:
          left:
            variable: document_id
          right:
            literal: '", status: PROCESSING }) { id status } }'

      empty_dict_processing:
        opcode: dict_create
        isReporter: true
        inputs: {}

      build_processing_body:
        opcode: dict_set
        isReporter: true
        inputs:
          d:
            node: empty_dict_processing
          key:
            literal: "query"
          value:
            node: build_processing_query

      do_callback_processing:
        opcode: http_post
        isReporter: true
        inputs:
          url:
            variable: api_url
          data:
            literal: null
          json:
            node: build_processing_body
          headers:
            node: callback_headers

      try_callback_processing:
        opcode: control_try
        next: save_step1_end
        inputs:
          TRY:
            branch: trigger_callback_processing
          CATCH1:
            exception_type: "Exception"
            var: "error_msg"
            body:
              branch: warn_callback_processing

      trigger_callback_processing:
        opcode: data_set_variable_to
        next: print_callback_processing_ok
        inputs:
          VARIABLE:
            literal: "callback_result"
          VALUE:
            node: do_callback_processing

      print_callback_processing_ok:
        opcode: io_print
        next: null
        inputs:
          STRING:
            literal: "[1/8] Callback: status -> PROCESSING\n"

      warn_callback_processing:
        opcode: io_print
        next: null
        inputs:
          STRING:
            literal: "[1/8] Callback: status -> PROCESSING (skipped - API unavailable)\n"

      get_step1_end:
        opcode: util_time_now
        isReporter: true
        inputs: {}

      save_step1_end:
        opcode: data_set_variable_to
        next: print_step1_done
        inputs:
          VARIABLE:
            literal: "step_t1"
          VALUE:
            node: get_step1_end

      step1_duration:
        opcode: util_format_duration
        isReporter: true
        inputs:
          start:
            variable: step1_t0
          end:
            variable: step_t1

      step1_done_msg:
        opcode: string_format
        isReporter: true
        inputs:
          template:
            literal: "       ({0})\n"
          VALUES:
            node: step1_duration

      print_step1_done:
        opcode: io_print
        next: save_step2_start
        inputs:
          STRING:
            node: step1_done_msg

      # ========================================================================
      # STEP 2: Create GCS Client
      # ========================================================================
      get_step2_start:
        opcode: util_time_now
        isReporter: true
        inputs: {}

      save_step2_start:
        opcode: data_set_variable_to
        next: print_step2
        inputs:
          VARIABLE:
            literal: "step2_t0"
          VALUE:
            node: get_step2_start

      print_step2:
        opcode: io_print
        next: create_gcs_client
        inputs:
          STRING:
            literal: "[2/8] Criando cliente GCS... "

      do_create_gcs_client:
        opcode: gcs_create_client
        isReporter: true
        inputs: {}

      create_gcs_client:
        opcode: data_set_variable_to
        next: save_step2_end
        inputs:
          VARIABLE:
            literal: "gcs_client"
          VALUE:
            node: do_create_gcs_client

      get_step2_end:
        opcode: util_time_now
        isReporter: true
        inputs: {}

      save_step2_end:
        opcode: data_set_variable_to
        next: print_step2_done
        inputs:
          VARIABLE:
            literal: "step_t1"
          VALUE:
            node: get_step2_end

      step2_duration:
        opcode: util_format_duration
        isReporter: true
        inputs:
          start:
            variable: step2_t0
          end:
            variable: step_t1

      step2_done_msg:
        opcode: string_format
        isReporter: true
        inputs:
          template:
            literal: "OK ({0})\n"
          VALUES:
            node: step2_duration

      print_step2_done:
        opcode: io_print
        next: save_step3_start
        inputs:
          STRING:
            node: step2_done_msg

      # ========================================================================
      # STEP 3: Download PDF from GCS
      # ========================================================================
      get_step3_start:
        opcode: util_time_now
        isReporter: true
        inputs: {}

      save_step3_start:
        opcode: data_set_variable_to
        next: print_step3
        inputs:
          VARIABLE:
            literal: "step3_t0"
          VALUE:
            node: get_step3_start

      print_step3:
        opcode: io_print
        next: download_pdf
        inputs:
          STRING:
            literal: "[3/8] Baixando PDF do GCS... "

      do_download_pdf:
        opcode: gcs_download_object_as_bytes
        isReporter: true
        inputs:
          client:
            variable: gcs_client
          bucket_name:
            variable: bucket
          object_name:
            variable: objeto

      download_pdf:
        opcode: data_set_variable_to
        next: save_step3_end
        inputs:
          VARIABLE:
            literal: "pdf_bytes"
          VALUE:
            node: do_download_pdf

      get_step3_end:
        opcode: util_time_now
        isReporter: true
        inputs: {}

      save_step3_end:
        opcode: data_set_variable_to
        next: print_step3_done
        inputs:
          VARIABLE:
            literal: "step_t1"
          VALUE:
            node: get_step3_end

      step3_duration:
        opcode: util_format_duration
        isReporter: true
        inputs:
          start:
            variable: step3_t0
          end:
            variable: step_t1

      step3_done_msg:
        opcode: string_format
        isReporter: true
        inputs:
          template:
            literal: "OK ({0})\n"
          VALUES:
            node: step3_duration

      print_step3_done:
        opcode: io_print
        next: save_step4_start
        inputs:
          STRING:
            node: step3_done_msg

      # ========================================================================
      # STEP 4: Connect to pgVector
      # ========================================================================
      get_step4_start:
        opcode: util_time_now
        isReporter: true
        inputs: {}

      save_step4_start:
        opcode: data_set_variable_to
        next: print_step4
        inputs:
          VARIABLE:
            literal: "step4_t0"
          VALUE:
            node: get_step4_start

      print_step4:
        opcode: io_print
        next: connect_pgvector
        inputs:
          STRING:
            literal: "[4/8] Conectando ao pgVector... "

      do_connect_pgvector:
        opcode: pgvector_connect
        isReporter: true
        inputs:
          dsn:
            variable: pgvector_dsn

      connect_pgvector:
        opcode: data_set_variable_to
        next: save_step4_end
        inputs:
          VARIABLE:
            literal: "pgvector_pool"
          VALUE:
            node: do_connect_pgvector

      get_step4_end:
        opcode: util_time_now
        isReporter: true
        inputs: {}

      save_step4_end:
        opcode: data_set_variable_to
        next: print_step4_done
        inputs:
          VARIABLE:
            literal: "step_t1"
          VALUE:
            node: get_step4_end

      step4_duration:
        opcode: util_format_duration
        isReporter: true
        inputs:
          start:
            variable: step4_t0
          end:
            variable: step_t1

      step4_done_msg:
        opcode: string_format
        isReporter: true
        inputs:
          template:
            literal: "OK ({0})\n"
          VALUES:
            node: step4_duration

      print_step4_done:
        opcode: io_print
        next: save_step5_start
        inputs:
          STRING:
            node: step4_done_msg

      # ========================================================================
      # STEP 5: Create Collection (if not exists)
      # ========================================================================
      get_step5_start:
        opcode: util_time_now
        isReporter: true
        inputs: {}

      save_step5_start:
        opcode: data_set_variable_to
        next: print_step5
        inputs:
          VARIABLE:
            literal: "step5_t0"
          VALUE:
            node: get_step5_start

      print_step5:
        opcode: io_print
        next: create_collection
        inputs:
          STRING:
            literal: "[5/8] Criando collection (se necessario)... "

      do_create_collection:
        opcode: pgvector_create_collection
        isReporter: true
        inputs:
          pool:
            variable: pgvector_pool
          name:
            variable: collection
          vector_size:
            literal: 768

      create_collection:
        opcode: control_if_else
        next: save_step6_start
        inputs:
          CONDITION:
            node: do_create_collection
          THEN:
            branch: save_step5_end_created
          ELSE:
            branch: save_step5_end_exists

      # Branch: Collection was created
      get_step5_end_created:
        opcode: util_time_now
        isReporter: true
        inputs: {}

      save_step5_end_created:
        opcode: data_set_variable_to
        next: print_created
        inputs:
          VARIABLE:
            literal: "step_t1"
          VALUE:
            node: get_step5_end_created

      step5_duration_created:
        opcode: util_format_duration
        isReporter: true
        inputs:
          start:
            variable: step5_t0
          end:
            variable: step_t1

      step5_created_msg:
        opcode: string_format
        isReporter: true
        inputs:
          template:
            literal: "Criada ({0})\n"
          VALUES:
            node: step5_duration_created

      print_created:
        opcode: io_print
        next: null
        inputs:
          STRING:
            node: step5_created_msg

      # Branch: Collection already exists
      get_step5_end_exists:
        opcode: util_time_now
        isReporter: true
        inputs: {}

      save_step5_end_exists:
        opcode: data_set_variable_to
        next: print_exists
        inputs:
          VARIABLE:
            literal: "step_t1"
          VALUE:
            node: get_step5_end_exists

      step5_duration_exists:
        opcode: util_format_duration
        isReporter: true
        inputs:
          start:
            variable: step5_t0
          end:
            variable: step_t1

      step5_exists_msg:
        opcode: string_format
        isReporter: true
        inputs:
          template:
            literal: "Ja existe ({0})\n"
          VALUES:
            node: step5_duration_exists

      print_exists:
        opcode: io_print
        next: null
        inputs:
          STRING:
            node: step5_exists_msg

      # ========================================================================
      # STEP 6: Extract text from PDF bytes (per page)
      # ========================================================================
      get_step6_start:
        opcode: util_time_now
        isReporter: true
        inputs: {}

      save_step6_start:
        opcode: data_set_variable_to
        next: print_step6
        inputs:
          VARIABLE:
            literal: "step6_t0"
          VALUE:
            node: get_step6_start

      print_step6:
        opcode: io_print
        next: extract_pdf
        inputs:
          STRING:
            literal: "[6/8] Extraindo texto do PDF... "

      do_extract_pdf:
        opcode: pdf_extract_pages_from_bytes
        isReporter: true
        inputs:
          data:
            variable: pdf_bytes

      extract_pdf:
        opcode: data_set_variable_to
        next: store_page_count
        inputs:
          VARIABLE:
            literal: "pdf_pages"
          VALUE:
            node: do_extract_pdf

      get_page_count:
        opcode: list_length
        isReporter: true
        inputs:
          items:
            variable: pdf_pages

      store_page_count:
        opcode: data_set_variable_to
        next: save_step6_end
        inputs:
          VARIABLE:
            literal: "page_count"
          VALUE:
            node: get_page_count

      get_step6_end:
        opcode: util_time_now
        isReporter: true
        inputs: {}

      save_step6_end:
        opcode: data_set_variable_to
        next: print_step6_done
        inputs:
          VARIABLE:
            literal: "step_t1"
          VALUE:
            node: get_step6_end

      page_count_str:
        opcode: str
        isReporter: true
        inputs:
          value:
            variable: page_count

      chunk_count_str:
        opcode: str
        isReporter: true
        inputs:
          value:
            variable: chunk_count

      step6_duration:
        opcode: util_format_duration
        isReporter: true
        inputs:
          start:
            variable: step6_t0
          end:
            variable: step_t1

      step6_done_msg:
        opcode: string_format
        isReporter: true
        inputs:
          template:
            literal: "{0} paginas extraidas ({1})\n"
          VALUES:
            node: page_count_str
          VALUE_1:
            node: step6_duration

      print_step6_done:
        opcode: io_print
        next: chunk_text
        inputs:
          STRING:
            node: step6_done_msg

      # ========================================================================
      # STEP 7: Chunk, embed, and upsert
      # ========================================================================
      do_chunk_pages:
        opcode: text_chunk_pages_smart
        isReporter: true
        inputs:
          pages:
            variable: pdf_pages
          chunk_size:
            variable: chunk_size
          overlap:
            variable: overlap

      chunk_text:
        opcode: data_set_variable_to
        next: store_chunk_count
        inputs:
          VARIABLE:
            literal: "chunks"
          VALUE:
            node: do_chunk_pages

      get_chunk_count:
        opcode: list_length
        isReporter: true
        inputs:
          items:
            variable: chunks

      store_chunk_count:
        opcode: data_set_variable_to
        next: extract_chunk_texts
        inputs:
          VARIABLE:
            literal: "chunk_count"
          VALUE:
            node: get_chunk_count

      # Extract text strings from chunk dicts for embedding using list_pluck
      do_extract_chunk_texts:
        opcode: list_pluck
        isReporter: true
        inputs:
          items:
            variable: chunks
          key:
            literal: "text"

      extract_chunk_texts:
        opcode: data_set_variable_to
        next: generate_embeddings
        inputs:
          VARIABLE:
            literal: "chunk_texts"
          VALUE:
            node: do_extract_chunk_texts

      do_generate_embeddings:
        opcode: embedding_create_batch
        isReporter: true
        inputs:
          texts:
            variable: chunk_texts
          project:
            variable: projeto_gcp
          location:
            literal: "us-central1"
          model:
            literal: "text-multilingual-embedding-002"
          task_type:
            literal: "RETRIEVAL_DOCUMENT"

      generate_embeddings:
        opcode: data_set_variable_to
        next: save_step7_start
        inputs:
          VARIABLE:
            literal: "embeddings"
          VALUE:
            node: do_generate_embeddings

      get_step7_start:
        opcode: util_time_now
        isReporter: true
        inputs: {}

      save_step7_start:
        opcode: data_set_variable_to
        next: print_step7
        inputs:
          VARIABLE:
            literal: "step7_t0"
          VALUE:
            node: get_step7_start

      print_step7:
        opcode: io_print
        next: build_metadata
        inputs:
          STRING:
            literal: "[7/8] Construindo payloads e salvando no pgVector... "

      # Build metadata dict for rag_build_chunk_payloads
      metadata_base:
        opcode: dict_create
        isReporter: true
        inputs: {}

      metadata_with_source:
        opcode: dict_set
        isReporter: true
        inputs:
          d:
            node: metadata_base
          key:
            literal: "source"
          value:
            variable: source_path

      metadata_with_livro_id:
        opcode: dict_set
        isReporter: true
        inputs:
          d:
            node: metadata_with_source
          key:
            literal: "livro_id"
          value:
            variable: livro_id

      metadata_with_workspace_id:
        opcode: dict_set
        isReporter: true
        inputs:
          d:
            node: metadata_with_livro_id
          key:
            literal: "workspace_id"
          value:
            variable: workspace_id

      metadata_with_document_id:
        opcode: dict_set
        isReporter: true
        inputs:
          d:
            node: metadata_with_workspace_id
          key:
            literal: "document_id"
          value:
            variable: document_id

      metadata_with_file_name:
        opcode: dict_set
        isReporter: true
        inputs:
          d:
            node: metadata_with_document_id
          key:
            literal: "file_name"
          value:
            variable: file_name

      build_metadata:
        opcode: data_set_variable_to
        next: do_build_payloads
        inputs:
          VARIABLE:
            literal: "metadata"
          VALUE:
            node: metadata_with_file_name

      # Call rag_build_chunk_payloads (replaces ~240-line build loop)
      do_rag_build:
        opcode: rag_build_chunk_payloads
        isReporter: true
        inputs:
          chunks:
            variable: chunks
          metadata:
            variable: metadata

      do_build_payloads:
        opcode: data_set_variable_to
        next: extract_ids
        inputs:
          VARIABLE:
            literal: "build_result"
          VALUE:
            node: do_rag_build

      get_built_ids:
        opcode: dict_get
        isReporter: true
        inputs:
          d:
            variable: build_result
          key:
            literal: "ids"

      extract_ids:
        opcode: data_set_variable_to
        next: extract_payloads
        inputs:
          VARIABLE:
            literal: "ids"
          VALUE:
            node: get_built_ids

      get_built_payloads:
        opcode: dict_get
        isReporter: true
        inputs:
          d:
            variable: build_result
          key:
            literal: "payloads"

      extract_payloads:
        opcode: data_set_variable_to
        next: do_upsert
        inputs:
          VARIABLE:
            literal: "payloads"
          VALUE:
            node: get_built_payloads

      # ========================================================================
      # Perform batch upsert to pgVector
      # ========================================================================
      do_pgvector_upsert:
        opcode: pgvector_upsert_batch
        isReporter: true
        inputs:
          pool:
            variable: pgvector_pool
          collection:
            variable: collection
          point_ids:
            variable: ids
          vectors:
            variable: embeddings
          payloads:
            variable: payloads

      do_upsert:
        opcode: control_if_else
        next: disconnect_pgvector
        inputs:
          CONDITION:
            node: do_pgvector_upsert
          THEN:
            branch: save_step7_end_ok
          ELSE:
            branch: save_step7_end_fail

      # Branch: Upsert succeeded
      get_step7_end_ok:
        opcode: util_time_now
        isReporter: true
        inputs: {}

      save_step7_end_ok:
        opcode: data_set_variable_to
        next: print_upsert_done
        inputs:
          VARIABLE:
            literal: "step_t1"
          VALUE:
            node: get_step7_end_ok

      step7_duration_ok:
        opcode: util_format_duration
        isReporter: true
        inputs:
          start:
            variable: step7_t0
          end:
            variable: step_t1

      step7_ok_msg:
        opcode: string_format
        isReporter: true
        inputs:
          template:
            literal: "OK ({0})\n"
          VALUES:
            node: step7_duration_ok

      print_upsert_done:
        opcode: io_print
        next: null
        inputs:
          STRING:
            node: step7_ok_msg

      # Branch: Upsert failed
      get_step7_end_fail:
        opcode: util_time_now
        isReporter: true
        inputs: {}

      save_step7_end_fail:
        opcode: data_set_variable_to
        next: print_upsert_failed
        inputs:
          VARIABLE:
            literal: "step_t1"
          VALUE:
            node: get_step7_end_fail

      step7_duration_fail:
        opcode: util_format_duration
        isReporter: true
        inputs:
          start:
            variable: step7_t0
          end:
            variable: step_t1

      step7_fail_msg:
        opcode: string_format
        isReporter: true
        inputs:
          template:
            literal: "FALHOU! ({0})\n"
          VALUES:
            node: step7_duration_fail

      print_upsert_failed:
        opcode: io_print
        next: null
        inputs:
          STRING:
            node: step7_fail_msg

      # ========================================================================
      # CLEANUP - Close clients
      # ========================================================================
      do_disconnect_pgvector:
        opcode: pgvector_disconnect
        isReporter: true
        inputs:
          pool:
            variable: pgvector_pool

      disconnect_pgvector:
        opcode: data_set_variable_to
        next: close_gcs
        inputs:
          VARIABLE:
            literal: "pgvector_pool"
          VALUE:
            node: do_disconnect_pgvector

      do_close_gcs:
        opcode: gcs_close_client
        isReporter: true
        inputs:
          client:
            variable: gcs_client

      close_gcs:
        opcode: data_set_variable_to
        next: save_step8_start
        inputs:
          VARIABLE:
            literal: "gcs_client"
          VALUE:
            node: do_close_gcs

      # ========================================================================
      # STEP 8: Callback INDEXED status to API
      # ========================================================================
      get_step8_start:
        opcode: util_time_now
        isReporter: true
        inputs: {}

      save_step8_start:
        opcode: data_set_variable_to
        next: try_callback_indexed
        inputs:
          VARIABLE:
            literal: "step8_t0"
          VALUE:
            node: get_step8_start

      # Build GraphQL mutation body for INDEXED status with totalChunks and totalPages
      # Note: chunk_count_str and page_count_str reporters are defined in step 6 section

      build_indexed_query:
        opcode: operator_add
        isReporter: true
        inputs:
          left:
            literal: 'mutation { updateDocumentStatus(input: { documentId: "'
          right:
            node: indexed_query_2

      indexed_query_2:
        opcode: operator_add
        isReporter: true
        inputs:
          left:
            variable: document_id
          right:
            node: indexed_query_3

      indexed_query_3:
        opcode: operator_add
        isReporter: true
        inputs:
          left:
            literal: '", status: INDEXED, totalChunks: '
          right:
            node: indexed_query_4

      indexed_query_4:
        opcode: operator_add
        isReporter: true
        inputs:
          left:
            node: chunk_count_str
          right:
            node: indexed_query_5

      indexed_query_5:
        opcode: operator_add
        isReporter: true
        inputs:
          left:
            literal: ", totalPages: "
          right:
            node: indexed_query_6

      indexed_query_6:
        opcode: operator_add
        isReporter: true
        inputs:
          left:
            node: page_count_str
          right:
            literal: ' }) { id status } }'

      empty_dict_indexed:
        opcode: dict_create
        isReporter: true
        inputs: {}

      build_indexed_body:
        opcode: dict_set
        isReporter: true
        inputs:
          d:
            node: empty_dict_indexed
          key:
            literal: "query"
          value:
            node: build_indexed_query

      do_callback_indexed:
        opcode: http_post
        isReporter: true
        inputs:
          url:
            variable: api_url
          data:
            literal: null
          json:
            node: build_indexed_body
          headers:
            node: callback_headers

      try_callback_indexed:
        opcode: control_try
        next: save_step8_end
        inputs:
          TRY:
            branch: trigger_callback_indexed
          CATCH1:
            exception_type: "Exception"
            var: "error_msg"
            body:
              branch: warn_callback_indexed

      trigger_callback_indexed:
        opcode: data_set_variable_to
        next: print_callback_indexed_ok
        inputs:
          VARIABLE:
            literal: "callback_result"
          VALUE:
            node: do_callback_indexed

      print_callback_indexed_ok:
        opcode: io_print
        next: null
        inputs:
          STRING:
            literal: "[8/8] Callback: status -> INDEXED\n"

      warn_callback_indexed:
        opcode: io_print
        next: null
        inputs:
          STRING:
            literal: "[8/8] Callback: status -> INDEXED (skipped - API unavailable)\n"

      get_step8_end:
        opcode: util_time_now
        isReporter: true
        inputs: {}

      save_step8_end:
        opcode: data_set_variable_to
        next: print_step8_done
        inputs:
          VARIABLE:
            literal: "step_t1"
          VALUE:
            node: get_step8_end

      step8_duration:
        opcode: util_format_duration
        isReporter: true
        inputs:
          start:
            variable: step8_t0
          end:
            variable: step_t1

      step8_done_msg:
        opcode: string_format
        isReporter: true
        inputs:
          template:
            literal: "       ({0})\n"
          VALUES:
            node: step8_duration

      print_step8_done:
        opcode: io_print
        next: print_footer
        inputs:
          STRING:
            node: step8_done_msg

      # ========================================================================
      # FOOTER
      # ========================================================================
      print_footer:
        opcode: io_print
        next: print_success
        inputs:
          STRING:
            literal: "\n================================================================================\n"

      success_msg_part1:
        opcode: operator_add
        isReporter: true
        inputs:
          left:
            literal: "SUCESSO: Indexados "
          right:
            node: chunk_count_str

      success_msg_part2:
        opcode: operator_add
        isReporter: true
        inputs:
          left:
            node: success_msg_part1
          right:
            literal: " chunks do livro '"

      success_msg_part3:
        opcode: operator_add
        isReporter: true
        inputs:
          left:
            node: success_msg_part2
          right:
            variable: livro_id

      success_msg_part4:
        opcode: operator_add
        isReporter: true
        inputs:
          left:
            node: success_msg_part3
          right:
            literal: "' na collection '"

      success_msg_part5:
        opcode: operator_add
        isReporter: true
        inputs:
          left:
            node: success_msg_part4
          right:
            variable: collection

      success_msg:
        opcode: operator_add
        isReporter: true
        inputs:
          left:
            node: success_msg_part5
          right:
            literal: "'\n"

      print_success:
        opcode: io_print
        next: print_total_time
        inputs:
          STRING:
            node: success_msg

      # Total pipeline time
      get_pipeline_end:
        opcode: util_time_now
        isReporter: true
        inputs: {}

      total_duration:
        opcode: util_format_duration
        isReporter: true
        inputs:
          start:
            variable: pipeline_t0
          end:
            node: get_pipeline_end

      total_time_msg:
        opcode: string_format
        isReporter: true
        inputs:
          template:
            literal: "Tempo total: {0}\n"
          VALUES:
            node: total_duration

      print_total_time:
        opcode: io_print
        next: print_final_separator
        inputs:
          STRING:
            node: total_time_msg

      print_final_separator:
        opcode: io_print
        next: null
        inputs:
          STRING:
            literal: "================================================================================\n\n"
