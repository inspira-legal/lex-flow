# Vault - Document Q&A (RAG Pipeline)
#
# Semantic search + AI answer for legal documents in the personal vault.
# 1. Embeds the user's question (RETRIEVAL_QUERY)
# 2. Searches pgVector with workspace_id filtering
# 3. Optionally applies BM25 reranking for hybrid search
# 4. Uses AI to generate an answer grounded in the retrieved context
# 5. Returns answer + structured highlights with page/line citations
#
# Run via CLI:
#   lexflow examples/showcase/vault/ask_book.yaml \
#     --input question="Qual a cláusula de rescisão?" \
#     --input workspace_id=62b9d55915370b1b00a1f86b
#
# Output format:
#   {
#     "answer": "A resposta gerada pela IA...",
#     "highlights": [
#       { "text": "...", "file_name": "contrato.pdf", "page_start": 3, "page_end": 3, "line_start": 45, "line_end": 62, "score": 0.87, "document_id": "62b...", "chunk_index": 5 },
#       ...
#     ]
#   }
#
# Requirements:
#   pip install lexflow[pgvector,rag,ai]
#   gcloud auth application-default login
#   PostgreSQL with pgvector extension

workflows:
  - name: main
    interface:
      inputs: [question, workspace_id, folder_id, num_results, rerank, rerank_alpha]
      outputs: []
    variables:
      # Input parameters
      question: ""
      workspace_id: ""
      folder_id: ""
      gcp_project: "inspira-development"
      collection_name: "documents"
      num_results: 8
      pgvector_dsn: "postgresql://vault:vault@localhost/vault"
      rerank: true
      rerank_alpha: 0.6
      # Search filters
      search_filters: null
      # pgVector pool
      pgvector_pool: null
      # Search results
      question_embedding: null
      search_results: null
      results_count: 0
      # Context building
      context_text: ""
      current_index: 0
      current_result: null
      current_payload: null
      current_text: ""
      current_file: ""
      current_page_start: ""
      current_page_end: ""
      current_line_start: ""
      current_line_end: ""
      current_score: 0
      current_document_id: ""
      current_chunk_index: 0
      # Output - structured highlights
      highlights: []
      # AI components
      model: null
      rag_agent: null
      full_prompt: ""
      answer: ""
      # Final result
      resultado_final: null
    nodes:
      start:
        opcode: workflow_start
        next: print_header
        inputs: {}

      # ========================================================================
      # HEADER
      # ========================================================================
      print_header:
        opcode: io_print
        next: print_question_header
        inputs:
          STRING:
            literal: "\n================================================================================\n                   VAULT - DOCUMENT Q&A (RAG)\n================================================================================\n\n"

      print_question_header:
        opcode: io_print
        next: print_question_value
        inputs:
          STRING:
            literal: "Pergunta: "

      format_question_display:
        opcode: operator_add
        isReporter: true
        inputs:
          left:
            variable: question
          right:
            literal: "\n\n"

      print_question_value:
        opcode: io_print
        next: print_retrieving
        inputs:
          STRING:
            node: format_question_display

      # ========================================================================
      # RETRIEVAL - Connect to pgVector and search
      # ========================================================================
      print_retrieving:
        opcode: io_print
        next: store_pgvector_pool
        inputs:
          STRING:
            literal: "[1/3] Buscando contexto relevante...\n"

      # Connect to pgVector
      connect_pgvector:
        opcode: pgvector_connect
        isReporter: true
        inputs:
          dsn:
            variable: pgvector_dsn

      store_pgvector_pool:
        opcode: data_set_variable_to
        next: store_question_embedding
        inputs:
          VARIABLE:
            literal: "pgvector_pool"
          VALUE:
            node: connect_pgvector

      # Create embedding for the question (RETRIEVAL_QUERY for search)
      create_question_embedding:
        opcode: embedding_create
        isReporter: true
        inputs:
          text:
            variable: question
          project:
            variable: gcp_project
          location:
            literal: "us-central1"
          model:
            literal: "text-multilingual-embedding-002"
          task_type:
            literal: "RETRIEVAL_QUERY"

      store_question_embedding:
        opcode: data_set_variable_to
        next: build_search_filters
        inputs:
          VARIABLE:
            literal: "question_embedding"
          VALUE:
            node: create_question_embedding

      # Build search filters dict (workspace_id + optional folder_id)
      create_filters_base:
        opcode: dict_create
        isReporter: true
        inputs: {}

      filters_with_workspace:
        opcode: dict_set
        isReporter: true
        inputs:
          d:
            node: create_filters_base
          key:
            literal: "workspace_id"
          value:
            variable: workspace_id

      filters_with_folder:
        opcode: dict_set
        isReporter: true
        inputs:
          d:
            node: filters_with_workspace
          key:
            literal: "folder_id"
          value:
            variable: folder_id

      build_search_filters:
        opcode: data_set_variable_to
        next: store_search_results
        inputs:
          VARIABLE:
            literal: "search_filters"
          VALUE:
            node: filters_with_folder

      # Compute over-fetch limit (3x num_results) for reranking
      compute_fetch_limit:
        opcode: operator_multiply
        isReporter: true
        inputs:
          left:
            variable: num_results
          right:
            literal: 3

      # Search pgVector for relevant chunks (filtered by workspace_id)
      search_pgvector:
        opcode: pgvector_search
        isReporter: true
        inputs:
          pool:
            variable: pgvector_pool
          collection:
            variable: collection_name
          query_vector:
            variable: question_embedding
          limit:
            node: compute_fetch_limit
          filters:
            variable: search_filters

      store_search_results:
        opcode: data_set_variable_to
        next: check_rerank
        inputs:
          VARIABLE:
            literal: "search_results"
          VALUE:
            node: search_pgvector

      # Conditionally apply BM25 reranking
      check_rerank:
        opcode: control_if
        next: store_results_count
        inputs:
          CONDITION:
            variable: rerank
          THEN:
            branch: rerank_results

      # BM25 rerank search results
      do_rerank:
        opcode: bm25_rerank
        isReporter: true
        inputs:
          query:
            variable: question
          results:
            variable: search_results
          top_k:
            variable: num_results
          alpha:
            variable: rerank_alpha

      rerank_results:
        opcode: data_set_variable_to
        next: null
        inputs:
          VARIABLE:
            literal: "search_results"
          VALUE:
            node: do_rerank

      # Get results count
      get_results_count:
        opcode: list_length
        isReporter: true
        inputs:
          items:
            variable: search_results

      store_results_count:
        opcode: data_set_variable_to
        next: init_context
        inputs:
          VARIABLE:
            literal: "results_count"
          VALUE:
            node: get_results_count

      init_context:
        opcode: data_set_variable_to
        next: build_context_loop
        inputs:
          VARIABLE:
            literal: "current_index"
          VALUE:
            literal: 0

      # ========================================================================
      # BUILD CONTEXT - Loop through results, extract citations
      # ========================================================================
      build_context_loop:
        opcode: control_while
        next: print_found_context
        inputs:
          CONDITION:
            node: check_context_index
          BODY:
            branch: process_result

      check_context_index:
        opcode: operator_less_than
        isReporter: true
        inputs:
          left:
            variable: current_index
          right:
            variable: results_count

      # Process each search result
      process_result:
        opcode: data_set_variable_to
        next: extract_payload
        inputs:
          VARIABLE:
            literal: "current_result"
          VALUE:
            node: get_current_result

      get_current_result:
        opcode: list_get
        isReporter: true
        inputs:
          items:
            variable: search_results
          index:
            variable: current_index

      # Extract payload from result
      extract_payload:
        opcode: data_set_variable_to
        next: extract_text
        inputs:
          VARIABLE:
            literal: "current_payload"
          VALUE:
            node: get_payload

      get_payload:
        opcode: dict_get
        isReporter: true
        inputs:
          d:
            variable: current_result
          key:
            literal: "payload"

      # Extract score
      get_score:
        opcode: dict_get
        isReporter: true
        inputs:
          d:
            variable: current_result
          key:
            literal: "score"
          default:
            literal: 0

      # Extract text from payload
      extract_text:
        opcode: data_set_variable_to
        next: extract_metadata
        inputs:
          VARIABLE:
            literal: "current_text"
          VALUE:
            node: get_text

      get_text:
        opcode: dict_get
        isReporter: true
        inputs:
          d:
            variable: current_payload
          key:
            literal: "text"
          default:
            literal: ""

      # Extract metadata fields
      get_file_name:
        opcode: dict_get
        isReporter: true
        inputs:
          d:
            variable: current_payload
          key:
            literal: "file_name"
          default:
            literal: ""

      get_page_start:
        opcode: dict_get
        isReporter: true
        inputs:
          d:
            variable: current_payload
          key:
            literal: "page_start"
          default:
            literal: ""

      get_page_end:
        opcode: dict_get
        isReporter: true
        inputs:
          d:
            variable: current_payload
          key:
            literal: "page_end"
          default:
            literal: ""

      get_line_start:
        opcode: dict_get
        isReporter: true
        inputs:
          d:
            variable: current_payload
          key:
            literal: "line_start"
          default:
            literal: ""

      get_line_end:
        opcode: dict_get
        isReporter: true
        inputs:
          d:
            variable: current_payload
          key:
            literal: "line_end"
          default:
            literal: ""

      get_document_id:
        opcode: dict_get
        isReporter: true
        inputs:
          d:
            variable: current_payload
          key:
            literal: "document_id"
          default:
            literal: ""

      get_chunk_index:
        opcode: dict_get
        isReporter: true
        inputs:
          d:
            variable: current_payload
          key:
            literal: "chunk_index"
          default:
            literal: 0

      extract_metadata:
        opcode: data_set_variable_to
        next: store_file
        inputs:
          VARIABLE:
            literal: "current_score"
          VALUE:
            node: get_score

      store_file:
        opcode: data_set_variable_to
        next: store_page_start
        inputs:
          VARIABLE:
            literal: "current_file"
          VALUE:
            node: get_file_name

      store_page_start:
        opcode: data_set_variable_to
        next: store_page_end
        inputs:
          VARIABLE:
            literal: "current_page_start"
          VALUE:
            node: get_page_start

      store_page_end:
        opcode: data_set_variable_to
        next: store_line_start
        inputs:
          VARIABLE:
            literal: "current_page_end"
          VALUE:
            node: get_page_end

      store_line_start:
        opcode: data_set_variable_to
        next: store_line_end
        inputs:
          VARIABLE:
            literal: "current_line_start"
          VALUE:
            node: get_line_start

      store_line_end:
        opcode: data_set_variable_to
        next: store_document_id
        inputs:
          VARIABLE:
            literal: "current_line_end"
          VALUE:
            node: get_line_end

      store_document_id:
        opcode: data_set_variable_to
        next: store_chunk_index
        inputs:
          VARIABLE:
            literal: "current_document_id"
          VALUE:
            node: get_document_id

      store_chunk_index:
        opcode: data_set_variable_to
        next: build_highlight
        inputs:
          VARIABLE:
            literal: "current_chunk_index"
          VALUE:
            node: get_chunk_index

      # Build structured highlight object
      highlight_base:
        opcode: dict_create
        isReporter: true
        inputs: {}

      hl_with_text:
        opcode: dict_set
        isReporter: true
        inputs:
          d:
            node: highlight_base
          key:
            literal: "text"
          value:
            variable: current_text

      hl_with_file:
        opcode: dict_set
        isReporter: true
        inputs:
          d:
            node: hl_with_text
          key:
            literal: "file_name"
          value:
            variable: current_file

      hl_with_ps:
        opcode: dict_set
        isReporter: true
        inputs:
          d:
            node: hl_with_file
          key:
            literal: "page_start"
          value:
            variable: current_page_start

      hl_with_pe:
        opcode: dict_set
        isReporter: true
        inputs:
          d:
            node: hl_with_ps
          key:
            literal: "page_end"
          value:
            variable: current_page_end

      hl_with_ls:
        opcode: dict_set
        isReporter: true
        inputs:
          d:
            node: hl_with_pe
          key:
            literal: "line_start"
          value:
            variable: current_line_start

      hl_with_le:
        opcode: dict_set
        isReporter: true
        inputs:
          d:
            node: hl_with_ls
          key:
            literal: "line_end"
          value:
            variable: current_line_end

      hl_with_score:
        opcode: dict_set
        isReporter: true
        inputs:
          d:
            node: hl_with_le
          key:
            literal: "score"
          value:
            variable: current_score

      hl_with_document_id:
        opcode: dict_set
        isReporter: true
        inputs:
          d:
            node: hl_with_score
          key:
            literal: "document_id"
          value:
            variable: current_document_id

      hl_with_chunk_index:
        opcode: dict_set
        isReporter: true
        inputs:
          d:
            node: hl_with_document_id
          key:
            literal: "chunk_index"
          value:
            variable: current_chunk_index

      append_highlight:
        opcode: list_append
        isReporter: true
        inputs:
          items:
            variable: highlights
          value:
            node: hl_with_chunk_index

      build_highlight:
        opcode: data_set_variable_to
        next: append_to_context
        inputs:
          VARIABLE:
            literal: "highlights"
          VALUE:
            node: append_highlight

      # Append text to context with file/page/line citation
      append_to_context:
        opcode: data_set_variable_to
        next: increment_context_index
        inputs:
          VARIABLE:
            literal: "context_text"
          VALUE:
            node: build_context_entry

      build_context_entry:
        opcode: operator_add
        isReporter: true
        inputs:
          left:
            variable: context_text
          right:
            node: format_context_entry

      page_start_str:
        opcode: str
        isReporter: true
        inputs:
          value:
            variable: current_page_start

      page_end_str:
        opcode: str
        isReporter: true
        inputs:
          value:
            variable: current_page_end

      line_start_str:
        opcode: str
        isReporter: true
        inputs:
          value:
            variable: current_line_start

      line_end_str:
        opcode: str
        isReporter: true
        inputs:
          value:
            variable: current_line_end

      # Format: [Arquivo: contract.pdf | Páginas 3-4 | Linhas 45-62]
      format_context_entry:
        opcode: operator_add
        isReporter: true
        inputs:
          left:
            literal: "[Arquivo: "
          right:
            node: ctx_file_part

      ctx_file_part:
        opcode: operator_add
        isReporter: true
        inputs:
          left:
            variable: current_file
          right:
            node: ctx_page_part

      ctx_page_part:
        opcode: operator_add
        isReporter: true
        inputs:
          left:
            literal: " | Pág. "
          right:
            node: ctx_page_range

      ctx_page_range:
        opcode: operator_add
        isReporter: true
        inputs:
          left:
            node: page_start_str
          right:
            node: ctx_page_sep

      ctx_page_sep:
        opcode: operator_add
        isReporter: true
        inputs:
          left:
            literal: "-"
          right:
            node: ctx_line_part

      ctx_line_part:
        opcode: operator_add
        isReporter: true
        inputs:
          left:
            node: page_end_str
          right:
            node: ctx_line_label

      ctx_line_label:
        opcode: operator_add
        isReporter: true
        inputs:
          left:
            literal: " | Linhas "
          right:
            node: ctx_line_range

      ctx_line_range:
        opcode: operator_add
        isReporter: true
        inputs:
          left:
            node: line_start_str
          right:
            node: ctx_line_end

      ctx_line_end:
        opcode: operator_add
        isReporter: true
        inputs:
          left:
            literal: "-"
          right:
            node: ctx_closing

      ctx_closing:
        opcode: operator_add
        isReporter: true
        inputs:
          left:
            node: line_end_str
          right:
            node: ctx_text_part

      ctx_text_part:
        opcode: operator_add
        isReporter: true
        inputs:
          left:
            literal: "]\n"
          right:
            node: ctx_text_content

      ctx_text_content:
        opcode: operator_add
        isReporter: true
        inputs:
          left:
            variable: current_text
          right:
            literal: "\n\n"

      # Increment index
      increment_context_index:
        opcode: data_set_variable_to
        next: null
        inputs:
          VARIABLE:
            literal: "current_index"
          VALUE:
            node: next_context_index

      next_context_index:
        opcode: operator_add
        isReporter: true
        inputs:
          left:
            variable: current_index
          right:
            literal: 1

      # ========================================================================
      # PRINT FOUND CONTEXT INFO
      # ========================================================================
      print_found_context:
        opcode: io_print
        next: print_generating
        inputs:
          STRING:
            node: format_found_context

      results_count_str:
        opcode: str
        isReporter: true
        inputs:
          value:
            variable: results_count

      format_found_context:
        opcode: operator_add
        isReporter: true
        inputs:
          left:
            literal: "      Encontrados "
          right:
            node: format_found_context_2

      format_found_context_2:
        opcode: operator_add
        isReporter: true
        inputs:
          left:
            node: results_count_str
          right:
            literal: " trechos relevantes\n\n"

      # ========================================================================
      # AI GENERATION - Create agent and generate answer
      # ========================================================================
      print_generating:
        opcode: io_print
        next: store_model
        inputs:
          STRING:
            literal: "[2/3] Gerando resposta com IA...\n"

      # Create Vertex AI Model
      create_model:
        opcode: pydantic_ai_create_vertex_model
        isReporter: true
        inputs:
          model_name:
            literal: "gemini-2.0-flash"
          project:
            variable: gcp_project
          location:
            literal: "us-central1"

      store_model:
        opcode: data_set_variable_to
        next: store_rag_agent
        inputs:
          VARIABLE:
            literal: "model"
          VALUE:
            node: create_model

      # Create RAG Agent with specialized legal system prompt
      create_rag_agent:
        opcode: pydantic_ai_create_agent
        isReporter: true
        inputs:
          model:
            variable: model
          instructions:
            literal: |
              Você é um assistente jurídico especializado em análise de documentos legais.
              Responda apenas com base no contexto fornecido (trechos de documentos do acervo pessoal do advogado).
              Se o contexto não contiver informação suficiente, diga honestamente.
              Sempre cite o arquivo, página e linhas de onde veio a informação (ex: "contrato.pdf, pág. 3, linhas 45-62").
              Use linguagem técnico-jurídica quando apropriado.
              Responda em português.

      store_rag_agent:
        opcode: data_set_variable_to
        next: store_full_prompt
        inputs:
          VARIABLE:
            literal: "rag_agent"
          VALUE:
            node: create_rag_agent

      # Build the full prompt with context and question
      build_full_prompt:
        opcode: operator_add
        isReporter: true
        inputs:
          left:
            literal: "CONTEXTO:\n"
          right:
            node: build_full_prompt_2

      build_full_prompt_2:
        opcode: operator_add
        isReporter: true
        inputs:
          left:
            variable: context_text
          right:
            node: build_full_prompt_3

      build_full_prompt_3:
        opcode: operator_add
        isReporter: true
        inputs:
          left:
            literal: "\nPERGUNTA: "
          right:
            node: build_full_prompt_4

      build_full_prompt_4:
        opcode: operator_add
        isReporter: true
        inputs:
          left:
            variable: question
          right:
            literal: "\n\nResponda a pergunta baseado apenas no contexto fornecido. Cite o arquivo, página e linhas."

      store_full_prompt:
        opcode: data_set_variable_to
        next: store_answer
        inputs:
          VARIABLE:
            literal: "full_prompt"
          VALUE:
            node: build_full_prompt

      # Run the AI agent
      run_rag_agent:
        opcode: pydantic_ai_run
        isReporter: true
        inputs:
          agent:
            variable: rag_agent
          prompt:
            variable: full_prompt

      store_answer:
        opcode: data_set_variable_to
        next: print_step3
        inputs:
          VARIABLE:
            literal: "answer"
          VALUE:
            node: run_rag_agent

      print_step3:
        opcode: io_print
        next: print_answer_header
        inputs:
          STRING:
            literal: "[3/3] Resposta gerada!\n"

      # ========================================================================
      # OUTPUT - Print the answer nicely formatted
      # ========================================================================
      print_answer_header:
        opcode: io_print
        next: print_answer
        inputs:
          STRING:
            literal: "\n--------------------------------------------------------------------------------\nRESPOSTA\n--------------------------------------------------------------------------------\n\n"

      format_answer_output:
        opcode: operator_add
        isReporter: true
        inputs:
          left:
            variable: answer
          right:
            literal: "\n"

      print_answer:
        opcode: io_print
        next: print_footer
        inputs:
          STRING:
            node: format_answer_output

      # Footer
      print_footer:
        opcode: io_print
        next: build_result
        inputs:
          STRING:
            literal: "\n--------------------------------------------------------------------------------\n\n"

      # ========================================================================
      # BUILD FINAL RESULT - Return answer + trechos
      # ========================================================================
      create_result_dict:
        opcode: dict_create
        isReporter: true
        inputs: {}

      add_answer_to_result:
        opcode: dict_set
        isReporter: true
        inputs:
          d:
            node: create_result_dict
          key:
            literal: "answer"
          value:
            variable: answer

      add_highlights_to_result:
        opcode: dict_set
        isReporter: true
        inputs:
          d:
            node: add_answer_to_result
          key:
            literal: "highlights"
          value:
            variable: highlights

      build_result:
        opcode: data_set_variable_to
        next: return_result
        inputs:
          VARIABLE:
            literal: "resultado_final"
          VALUE:
            node: add_highlights_to_result

      return_result:
        opcode: workflow_return
        next: null
        inputs:
          VALUE:
            variable: resultado_final
